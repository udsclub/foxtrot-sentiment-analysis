{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.en import English\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from subprocess import run\n",
    "from fasttext import supervised, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152610, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>To an entire generation of filmgoers, it just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pixar classic is one of the best kids' movies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Apesar de representar um imenso avanço tecnoló...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>When Woody perks up in the opening scene, it's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Introduced not one but two indelible character...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  To an entire generation of filmgoers, it just ...\n",
       "1      1  Pixar classic is one of the best kids' movies ...\n",
       "2      1  Apesar de representar um imenso avanço tecnoló...\n",
       "3      1  When Woody perks up in the opening scene, it's...\n",
       "4      1  Introduced not one but two indelible character..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([pd.read_csv('reviews_rt_all.csv',sep='|'), \n",
    "                  pd.read_csv('imdb_small.csv',sep='|')], ignore_index=True)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data\n",
    "\n",
    "* Words with n't|'re|'s|'ve|'ll|'d were fixed for lemmatization\n",
    "* Actors could play in good and bad movies we attempted to remove them (at least such cases when their names are in brackets)\n",
    "* Digits, special signs and one-letter words were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redundant_signs = set(string.punctuation) - set(['.'])\n",
    "letters = [x for x in string.ascii_lowercase + '. ']\n",
    "\n",
    "def clean_data(inp_str):\n",
    "    inp_str = inp_str.lower()\n",
    "\n",
    "    # fix haven't|doesn't|shouldn't cases\n",
    "    inp_str = inp_str.replace(\"n't\", \" not\")\n",
    "    inp_str = inp_str.replace(\"'re\", \" are\")\n",
    "    inp_str = inp_str.replace(\"'s\", \" s\")\n",
    "    inp_str = inp_str.replace(\"'ve\", \" have\")\n",
    "    inp_str = inp_str.replace(\"'ll\", \" will\")\n",
    "    inp_str = inp_str.replace(\"'d\", \" d\")\n",
    "\n",
    "    # here may be actor's names, types of smth etc. I guess it's redundant info\n",
    "    # let's discuss of necessity of this block\n",
    "    bracket_words = re.findall('([\\(\\[\\{].+?[\\)\\]\\}])', inp_str)\n",
    "    for word in bracket_words:\n",
    "        inp_str = inp_str.replace(''.join(word), \"\")\n",
    "\n",
    "    # replace redundant_signs\n",
    "    for item in redundant_signs:\n",
    "        inp_str = inp_str.replace(item, ' ')\n",
    "\n",
    "    # replace digits\n",
    "    inp_str = re.sub('\\d', ' ', inp_str)\n",
    "    # replace two or more dots. 1 dot is remained as it separates sentences\n",
    "    inp_str = re.sub('\\.{1,10}', ' ', inp_str)\n",
    "    # replace one-letter words or just letters\n",
    "    inp_str = re.sub(r\"\\b[a-z]{1}\\b\", ' ', inp_str)\n",
    "\n",
    "    return ' '.join(list(filter(None, inp_str.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data:  (152610, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>To an entire generation of filmgoers, it just ...</td>\n",
       "      <td>to an entire generation of filmgoers it just m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pixar classic is one of the best kids' movies ...</td>\n",
       "      <td>pixar classic is one of the best kids movies o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Apesar de representar um imenso avanço tecnoló...</td>\n",
       "      <td>apesar de representar um imenso avanço tecnoló...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>When Woody perks up in the opening scene, it's...</td>\n",
       "      <td>when woody perks up in the opening scene it no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Introduced not one but two indelible character...</td>\n",
       "      <td>introduced not one but two indelible character...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  To an entire generation of filmgoers, it just ...   \n",
       "1      1  Pixar classic is one of the best kids' movies ...   \n",
       "2      1  Apesar de representar um imenso avanço tecnoló...   \n",
       "3      1  When Woody perks up in the opening scene, it's...   \n",
       "4      1  Introduced not one but two indelible character...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  to an entire generation of filmgoers it just m...  \n",
       "1  pixar classic is one of the best kids movies o...  \n",
       "2  apesar de representar um imenso avanço tecnoló...  \n",
       "3  when woody perks up in the opening scene it no...  \n",
       "4  introduced not one but two indelible character...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_text'] = data['text'].apply(clean_data)\n",
    "print('source data: ', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing data\n",
    "\n",
    "* Lemmatization was made with spacy pasckage\n",
    "* The word 'movie' was removed\n",
    "* Reviews with non ascii letters and empty reviews were removed\n",
    "* Labels were replaced with `__label__1` or `__label__0` because fastText requires obviously marked labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "def lem(line, nlp):\n",
    "    return ' '.join([word.lemma_ for word in nlp(line)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = ['movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finalize_data(df, nlp):\n",
    "    df['stemed_text'] = df['clean_text'].apply(lem, args=(nlp,))\n",
    "    df['stemed_text'] = df['stemed_text'].apply(\n",
    "        lambda x: ' '.join([item for item in x.split() if item not in stop_words]))\n",
    "    df['is_ascii'] = df['stemed_text'].apply(lambda x: set(x).issubset(letters))\n",
    "    df['letters'] = df['stemed_text'].apply(len)\n",
    "    df['new_label'] = df['label'].apply(lambda x: '__label__1 ' if x == 1 else '__label__0 ')\n",
    "\n",
    "    df = df[df['is_ascii'] == 1]\n",
    "    df = df[df['letters'] > 0]\n",
    "    df = df.reset_index()\n",
    "    df = df.ix[:, ['new_label', 'stemed_text']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned data:  (145204, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_label</th>\n",
       "      <th>stemed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>to an entire generation of filmgoers it just m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>pixar classic be one of the good kid of all time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>when woody perk up in the opening scene it not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>introduce not one but two indelible character ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>it be easy to see how virtually everything tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     new_label                                        stemed_text\n",
       "0  __label__1   to an entire generation of filmgoers it just m...\n",
       "1  __label__1    pixar classic be one of the good kid of all time\n",
       "2  __label__1   when woody perk up in the opening scene it not...\n",
       "3  __label__1   introduce not one but two indelible character ...\n",
       "4  __label__1   it be easy to see how virtually everything tha..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = finalize_data(data, nlp)\n",
    "print('cleaned data: ', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model learning and accuracy evaluation\n",
    "\n",
    "`train_test_split` was used for splitting and evaluation our model. \n",
    "\n",
    "https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md\n",
    "\n",
    "The main task is to train 1 clasifier on rt and imdb datasets. The main difference between data is that imdb has long reviews and rt's reviews are short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['stemed_text'], \n",
    "                                                    data['new_label'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=data['new_label'])\n",
    "\n",
    "pd.concat([y_train, X_train], axis = 1).to_csv('train_imdb_rt_vec_wo_sw.txt', header=False, encoding='utf-8', index=False)\n",
    "pd.concat([y_test, X_test], axis = 1).to_csv('test_imdb_rt_vec_wo_sw.txt', header=False, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run(\"fasttext supervised -input train_imdb_rt_vec_wo_sw.txt -lr 0.005 -epoch 15 -minCount 500 -dim 300 -output model_vec_wo_sw -pretrainedVectors wiki.en.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(X_train, X_test, y_train, y_test, model_file):\n",
    "\n",
    "    y_train = y_train.apply(lambda x: int(x.strip()[-1]))\n",
    "    y_test = y_test.apply(lambda x: int(x.strip()[-1]))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    classifier = load_model(model_file, label_prefix='__label__')\n",
    "    learning_time = time.time()\n",
    "    train_prediction = classifier.predict_proba(list(X_train))\n",
    "    test_prediction = classifier.predict_proba(list(X_test))\n",
    "    prediction_time = time.time()\n",
    "    train_predictions = [int(item[0][0]) for item in train_prediction]\n",
    "    test_predictions = [int(item[0][0]) for item in test_prediction]\n",
    "\n",
    "    print(\"=\" * 30)\n",
    "    print('****Results****')\n",
    "    print('Learning model: %d seconds' % round(learning_time - start_time, 2))\n",
    "    print('Cross-validation time: %d seconds' % round(prediction_time - learning_time, 2))\n",
    "    acc_tr = accuracy_score(y_train, train_predictions)\n",
    "    acc_te = accuracy_score(y_test, test_predictions)\n",
    "    print(\"Accuracy: train - {:.6}, test - {:.6}, diff - {:.6} \\n\".format(acc_tr, acc_te, acc_tr - acc_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "****Results****\n",
      "Learning model: 7 seconds\n",
      "Cross-validation time: 15 seconds\n",
      "Accuracy: train - 0.832658, test - 0.817568, diff - 0.0150893 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_score(X_train, X_test, y_train, y_test, 'model_vec_wo_sw.bin')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
